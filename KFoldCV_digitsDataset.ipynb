{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "91aae085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "digits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0c1a8c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0_0</th>\n",
       "      <th>pixel_0_1</th>\n",
       "      <th>pixel_0_2</th>\n",
       "      <th>pixel_0_3</th>\n",
       "      <th>pixel_0_4</th>\n",
       "      <th>pixel_0_5</th>\n",
       "      <th>pixel_0_6</th>\n",
       "      <th>pixel_0_7</th>\n",
       "      <th>pixel_1_0</th>\n",
       "      <th>pixel_1_1</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_6_6</th>\n",
       "      <th>pixel_6_7</th>\n",
       "      <th>pixel_7_0</th>\n",
       "      <th>pixel_7_1</th>\n",
       "      <th>pixel_7_2</th>\n",
       "      <th>pixel_7_3</th>\n",
       "      <th>pixel_7_4</th>\n",
       "      <th>pixel_7_5</th>\n",
       "      <th>pixel_7_6</th>\n",
       "      <th>pixel_7_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel_0_0  pixel_0_1  pixel_0_2  pixel_0_3  pixel_0_4  pixel_0_5  \\\n",
       "0        0.0        0.0        5.0       13.0        9.0        1.0   \n",
       "1        0.0        0.0        0.0       12.0       13.0        5.0   \n",
       "2        0.0        0.0        0.0        4.0       15.0       12.0   \n",
       "3        0.0        0.0        7.0       15.0       13.0        1.0   \n",
       "4        0.0        0.0        0.0        1.0       11.0        0.0   \n",
       "\n",
       "   pixel_0_6  pixel_0_7  pixel_1_0  pixel_1_1  ...  pixel_6_6  pixel_6_7  \\\n",
       "0        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "1        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "2        0.0        0.0        0.0        0.0  ...        5.0        0.0   \n",
       "3        0.0        0.0        0.0        8.0  ...        9.0        0.0   \n",
       "4        0.0        0.0        0.0        0.0  ...        0.0        0.0   \n",
       "\n",
       "   pixel_7_0  pixel_7_1  pixel_7_2  pixel_7_3  pixel_7_4  pixel_7_5  \\\n",
       "0        0.0        0.0        6.0       13.0       10.0        0.0   \n",
       "1        0.0        0.0        0.0       11.0       16.0       10.0   \n",
       "2        0.0        0.0        0.0        3.0       11.0       16.0   \n",
       "3        0.0        0.0        7.0       13.0       13.0        9.0   \n",
       "4        0.0        0.0        0.0        2.0       16.0        4.0   \n",
       "\n",
       "   pixel_7_6  pixel_7_7  \n",
       "0        0.0        0.0  \n",
       "1        0.0        0.0  \n",
       "2        9.0        0.0  \n",
       "3        0.0        0.0  \n",
       "4        0.0        0.0  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(digits.data, columns=digits.feature_names)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b30e362d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x258b4511bd0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# representing the pixel matrix in form of an image\n",
    "plt.gray()\n",
    "plt.matshow(digits.data[8].reshape(8, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a10ab053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# independent and dependent features\n",
    "x = digits.data\n",
    "y = digits.target\n",
    "# spliting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y ,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ef815d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the different models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "927b891b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Coding\\Personal\\Learning\\ML\\Practice_Scikit\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Coding\\Personal\\Learning\\ML\\Practice_Scikit\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Coding\\Personal\\Learning\\ML\\Practice_Scikit\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Coding\\Personal\\Learning\\ML\\Practice_Scikit\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "d:\\Coding\\Personal\\Learning\\ML\\Practice_Scikit\\ml\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic scores:  [0.95435685 0.98340249 0.97095436 0.96666667 0.95833333]\n",
      "Random forest scores:  [0.95850622 0.97925311 0.98340249 0.96666667 0.95833333]\n",
      "SVC scores:  [0.97925311 0.99170124 0.99585062 0.98333333 0.98333333]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "log_scores = cross_val_score(estimator=LogisticRegression(max_iter=100), X=x_train, y=y_train, cv=5)\n",
    "randomF_scores = cross_val_score(estimator=RandomForestClassifier(), X=x_train, y=y_train, cv=5)\n",
    "svm_scores = cross_val_score(estimator=SVC(), X=x_train, y=y_train, cv=5)\n",
    "print(\"Logistic scores: \",log_scores)\n",
    "print(\"Random forest scores: \",randomF_scores)\n",
    "print(\"SVC scores: \",svm_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4a0530e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = { \n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 0.01, 0.1, 1],    \n",
    "    'degree': [3]                  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "85e2be96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.9916839557399723)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SVC yields better, so using hyper parameter tuning on it\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid = GridSearchCV(estimator=SVC(), param_grid=param_grid, scoring='accuracy', cv=5)\n",
    "grid.fit(x_train, y_train)\n",
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8de16f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9848484848484849 \n",
      "\n",
      "report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        55\n",
      "           1       0.98      0.98      0.98        60\n",
      "           2       0.98      1.00      0.99        54\n",
      "           3       1.00      0.96      0.98        69\n",
      "           4       1.00      1.00      1.00        54\n",
      "           5       0.98      0.97      0.98        63\n",
      "           6       0.98      1.00      0.99        63\n",
      "           7       0.97      1.00      0.98        57\n",
      "           8       0.96      0.98      0.97        56\n",
      "           9       0.98      0.97      0.98        63\n",
      "\n",
      "    accuracy                           0.98       594\n",
      "   macro avg       0.98      0.99      0.99       594\n",
      "weighted avg       0.99      0.98      0.98       594\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = grid.predict(x_test)\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "print(f\"accuracy: {accuracy_score(y_test, y_pred)} \\n\")\n",
    "print(f\"report: {classification_report(y_test, y_pred)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
